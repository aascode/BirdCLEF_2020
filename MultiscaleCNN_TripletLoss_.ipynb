{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install tensorflow==2.2.0\n!pip install tensorflow_addons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n\nprint(tf.__version__)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers \nimport tensorflow_addons as tfa\n\nfrom keras.regularizers import l2\nfrom keras.utils import to_categorical\nfrom keras.models import load_model\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"X_train = np.load('/kaggle/input/birdclef-2020/X_train.npy')\ny_train = np.load('/kaggle/input/birdclef-2020/y_train.npy')\n\nX_val = np.load('/kaggle/input/birdclef-2020/X_val.npy')\ny_val = np.load('/kaggle/input/birdclef-2020/y_val.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train = np.concatenate((X_train, X_val))\n#y_train = np.concatenate((y_train, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[3000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train,X_train = (list(t) for t in zip(*sorted(zip(y_train, X_train))))\ny_val,X_val = (list(t) for t in zip(*sorted(zip(y_val, X_val))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nspecies = 960\nfor i in range(0,len(y_train)):\n    if(y_train[i] == nspecies):\n        break\ny_train,X_train = y_train[:i],X_train[:i]\n\nfor i in range(0,len(y_val)):\n    if(y_val[i] == nspecies):\n        break\ny_val,X_val = y_val[:i],X_val[:i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(y_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Organize to all batchs have positives and negatives anchors\n\ntuple_X = []\ntuple_y = []\n\nfor i in range(0,len(y_train),2):\n    if(i == len(y_train)-1):\n        tuple_X.append((X_train[i],X_train[i]))\n        tuple_y.append((y_train[i],y_train[i]))\n    else:    \n        tuple_X.append((X_train[i],X_train[i+1]))\n        tuple_y.append((y_train[i],y_train[i+1]))\n\ntuple_X_shuffled, tuple_y_shuffled = shuffle(tuple_X, tuple_y)\n\nX_shuffled = []\ny_shuffled = []\nfor i in range(0,len(tuple_y_shuffled)):\n    X_shuffled.append(tuple_X_shuffled[i][0])\n    X_shuffled.append(tuple_X_shuffled[i][1])\n    y_shuffled.append(tuple_y_shuffled[i][0])\n    y_shuffled.append(tuple_y_shuffled[i][1])\n\nX_train = np.array(X_shuffled)\ny_train = np.array(y_shuffled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Organize to all batchs have positives and negatives anchors\n\ntuple_X = []\ntuple_y = []\n\nfor i in range(0,len(y_val),2):\n    if(i == len(y_val)-1):\n        tuple_X.append((X_val[i],X_val[i]))\n        tuple_y.append((y_val[i],y_val[i]))\n    else:    \n        tuple_X.append((X_val[i],X_val[i+1]))\n        tuple_y.append((y_val[i],y_val[i+1]))\n\ntuple_X_shuffled, tuple_y_shuffled = shuffle(tuple_X, tuple_y)\n\nX_shuffled = []\ny_shuffled = []\nfor i in range(0,len(tuple_y_shuffled)):\n    X_shuffled.append(tuple_X_shuffled[i][0])\n    X_shuffled.append(tuple_X_shuffled[i][1])\n    y_shuffled.append(tuple_y_shuffled[i][0])\n    y_shuffled.append(tuple_y_shuffled[i][1])\n\nX_val = np.array(X_shuffled)\ny_val = np.array(y_shuffled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    \n    def __init__(self, image_filenames,labels, image_path,to_fit=True, batch_size=64):\n        self.labels = labels\n        self.image_filenames = image_filenames\n        self.image_path = image_path\n        self.to_fit = to_fit\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n\n    def __getitem__(self, index):\n        # Generate data\n        X = self._generate_X(index)\n\n        if self.to_fit:\n            y = self._generate_y(index)\n            return X, y\n        else:\n            return X\n\n    def _generate_X(self, idx):\n        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n        ret = []\n\n        for file_name in batch_x:\n            dict_data = np.load(self.image_path +str(file_name)+\".npz\")\n            data = dict_data['arr_0']\n            ret.append(data)\n\n        return np.array(ret)\n\n    def _generate_y(self, idx):\n        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n\n        return np.array(batch_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train, y_train = shuffle(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path = '/kaggle/input/birdclef-2020/train/train/'\nmy_train_generator = DataGenerator(X_train, y_train,image_path,batch_size=128)\nmy_val_generator = DataGenerator(X_val, y_val,image_path,batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wd = 0.000001\n\n#Template of Multiscale Analysis Module\ndef MAM(in_mam):\n    str1 = layers.Conv2D(64,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    \n    str2 = layers.Conv2D(32,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    str2 = layers.Conv2D(64,kernel_size=(3,3),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(str2)\n    \n    str3 = layers.Conv2D(32,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    str3 = layers.Conv2D(64,kernel_size=(5,5),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(str3)\n    \n    str4 = layers.Conv2D(32,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    str4 = layers.Conv2D(64,kernel_size=(7,7),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(str4)\n    \n    mam = layers.concatenate([str1,str2,str3,str4])\n    return mam\n\n#BEGIN OF MULTISCALE CNN\nInput = keras.Input(shape=(40, 200, 3))\n\n#CONV1\nx = layers.Conv2D(64, kernel_size=(3,3), strides=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(Input)\n#MAM1\nx = MAM(x)\n#CONV2\nx = layers.Conv2D(64, kernel_size=3,strides=(2,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\n#MAM2\nx = MAM(x)\n#CONV3\nx = layers.Conv2D(64, kernel_size=3,strides=(2,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\n#MAM1\nx = MAM(x)\n#CONV4\nx = layers.Conv2D(64, kernel_size=3,strides=(2,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\n#MAM1\nx = MAM(x)\n#CONV5\nx = layers.Conv2D(64, kernel_size=3,strides=(5,1), padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(256,activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\nx = layers.Dropout(0.5)(x)\nx = layers.Dense(256,activation='relu', kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\nx = layers.Dropout(0.5)(x)\nemb128 = layers.Dense(256,activation='linear')(x)\n\nmodel1 = keras.Model(inputs=Input, outputs=emb128, name=\"Multiscale_CNN\")\n\n#To see the summary of model uncoment here\n#model1.summary()\n#To see a plot of model uncoment here\n#keras.utils.plot_model(model1, \"deep_metric_learning.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_filepath = '/kaggle/working/'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    'model{epoch:08d}.h5',save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.compile(\n        optimizer=keras.optimizers.Adagrad(),\n        loss=tfa.losses.TripletSemiHardLoss())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model1.load_weights(\"/kaggle/working/model00000030.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model1.fit(my_train_generator,epochs=100,verbose=1,validation_data=my_val_generator,callbacks=[model_checkpoint_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"Loss\"\nplt.plot(history.history['loss'][:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Uncoment here to save the model in the Disk\n\n# serialize model to JSON\nmodel_json = model1.to_json()\nwith open(\"MultiScale-Triplet.json\", \"w\") as json_file:\n    json_file.write(model_json)\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get data to classify","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path = '/kaggle/input/birdclef-2020/train/train/'\npred_generator = DataGenerator(X_train, y_train, image_path, to_fit=False,batch_size=1)\npred_val_generator = DataGenerator(X_val, y_val, image_path, to_fit=False,batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train embeddings\n\npred = model1.predict(pred_generator)\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validation embeddings\n\npred_val = model1.predict(pred_val_generator)\npred_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pred\ny_train_onehot = keras.utils.to_categorical(y_train)\nX_val = pred_val\ny_val_onehot = keras.utils.to_categorical(y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MPL Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Input Layer\nInput = keras.Input(shape=(256))\n#Hidden Layer\nx = layers.Dense(units=256,activation='relu')(Input)\nx = layers.Dropout(0.5)(x)\n#Output to N Classes\nx = layers.Dense(units=nspecies,activation='softmax')(x)\n\nmodel2 = keras.Model(inputs=Input, outputs=x, name=\"MLP\")\n\n#To see the summary of model uncoment here\n#model2.summary()\n#To see a plot of model uncoment here\n#keras.utils.plot_model(model2, \"classification.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.compile(\n    optimizer=keras.optimizers.Adam(0.001), # 0.01 better results but overfit fast, other is 0.001 \n    loss=keras.losses.CategoricalCrossentropy(),\n    metrics=['accuracy']\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model2.load_weights('classifier.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model2.fit(X_train, y_train_onehot, verbose=1,batch_size=256,epochs=500,validation_data=(X_val, y_val_onehot))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the train things\nplt.plot(history.history['loss'][:])\nplt.plot(history.history['val_loss'][:])\nplt.title('model loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict from MLP\ny_train_pred = model2.predict(X_train)\ny_val_pred = model2.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_pred[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforming percent predictions to choose one classe\ndef my_predict(y_in_perc):\n    n_pred = np.zeros(len(y_in_perc),dtype=int) \n    for i in range(len(y_in_perc)):  \n        #if(y_in_perc[i].max() > 0.3):\n        n_pred[i] = y_in_perc[i].argmax()\n        #else:\n        #    n_pred[i] = -1\n    return n_pred \n\n\ny_train_pred = my_predict(y_train_pred)\ny_val_pred = my_predict(y_val_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_pred[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate training accuracy\ncorrect_preds = np.sum(y_train == y_train_pred, axis=0)\ntrain_acc = correct_preds / y_train.shape[0]\n\nprint(f'Training accuracy: {(train_acc * 100):.2f}')\n\n# calculate testing accuracy\ncorrect_preds = np.sum(y_val == y_val_pred, axis=0)\ntest_acc = correct_preds / y_val.shape[0]\n\nprint(f'Test accuracy: {(test_acc * 100):.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model2.to_json()\nwith open(\"Classifier.json\", \"w\") as json_file:\n    json_file.write(model_json)\nmodel2.save_weights(\"classifier.h5\")    \nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}