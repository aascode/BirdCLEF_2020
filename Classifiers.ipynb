{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libs"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nprint(tf.__version__)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers \n\n\n\nimport os,warnings,csv,shutil\nimport cv2\nimport math\n\nfrom tensorflow.keras.models import model_from_json","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Name of files and your labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.load('/kaggle/input/birdclef-2020/X_train.npy')\ny_train = np.load('/kaggle/input/birdclef-2020/y_train.npy')\n\nX_val = np.load('/kaggle/input/birdclef-2020/X_val.npy')\ny_val = np.load('/kaggle/input/birdclef-2020/y_val.npy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load json and create model\njson_file = open('../input/validate/MultiScale-Triplet.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nmultiscale = model_from_json(loaded_model_json)\n# load weights into new model\nmultiscale.load_weights(\"../input/validate/model00000035.h5\")\nprint(\"Loaded model from disk\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make a DataGenerator to get the numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    \n    def __init__(self, image_filenames,labels, image_path,to_fit=True, batch_size=64):\n        self.labels = labels\n        self.image_filenames = image_filenames\n        self.image_path = image_path\n        self.to_fit = to_fit\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n\n    def __getitem__(self, index):\n        # Generate data\n        X = self._generate_X(index)\n\n        if self.to_fit:\n            y = self._generate_y(index)\n            return X, y\n        else:\n            return X\n\n    def _generate_X(self, idx):\n        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n        ret = []\n\n        for file_name in batch_x:\n            dict_data = np.load(self.image_path +str(file_name)+\".npz\")\n            data = dict_data['arr_0']\n            ret.append(data)\n\n        return np.array(ret)\n\n    def _generate_y(self, idx):\n        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n\n        return np.array(batch_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Data to Classify"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path = '../input/birdclef-2020/train/train/'\npred_generator = DataGenerator(X_train, y_train, image_path, to_fit=False,batch_size=1)\npred_val_generator = DataGenerator(X_val, y_val, image_path, to_fit=False,batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train embeddings\npred = multiscale.predict(pred_generator)\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validation embeddings\npred_val = multiscale.predict(pred_val_generator)\npred_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform y_train and y_val to onehot way\nemb_train = pred\ny_train_onehot = keras.utils.to_categorical(y_train)\nemb_val = pred_val\ny_val_onehot = keras.utils.to_categorical(y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MPL Classifier"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Input Layer\nInput = keras.Input(shape=(128))\n#Hidden Layer\nx = layers.Dense(units=256,activation='relu')(Input)\nx = layers.Dropout(0.5)(x)\n#Output to N Classes\nx = layers.Dense(units=960,activation='softmax')(x)\n\nmlp = keras.Model(inputs=Input, outputs=x, name=\"MLP\")\n\n#To see the summary of model uncoment here\n#model2.summary()\n#To see a plot of model uncoment here\n#keras.utils.plot_model(model2, \"classification.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp.compile(\n    optimizer=keras.optimizers.Adam(0.001), \n    loss=keras.losses.CategoricalCrossentropy(),\n    metrics=['accuracy']\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = mlp.fit(emb_train, y_train_onehot, verbose=1,validation_data=(emb_val,y_val_onehot),batch_size=256,epochs=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = mlp.to_json()\nwith open(\"Classifier.json\", \"w\") as json_file:\n    json_file.write(model_json)\nmlp.save_weights(\"classifier.h5\")    \nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the train things\nplt.plot(history.history['loss'][:])\nplt.plot(history.history['val_loss'][:])\nplt.title('model loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classify and Get accuracy from 2 Classifiers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get The 2 Fist Classes\ndef my_predict(y_in_perc):\n    n_pred = [[],[]]\n    n_pred[0] = np.zeros(len(y_in_perc),dtype=int)\n    n_pred[1] = np.zeros(len(y_in_perc),dtype=int)\n    \n    for i in range(len(y_in_perc)):  \n        #if(y_in_perc[i].max() > 0.3):\n        ma1 = 0\n        ma2 = 0\n        \n        for j in range(y_in_perc[i].shape[0]):\n            if(y_in_perc[i][j] > y_in_perc[i][ma1]):\n                ma2 = ma1\n                ma1 = j\n            elif (y_in_perc[i][j] > y_in_perc[i][ma2]):\n                ma2 = j\n                \n                \n        n_pred[0][i] = ma1\n        n_pred[1][i] = ma2\n        \n    return n_pred ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Evaluate(y_train_pred,y_val_pred):  \n    # calculate training accuracy\n    correct_preds = 0\n    for i in range(len(y_train)):\n        if (y_train[i] == y_train_pred[0][i] ):\n            correct_preds  += 1\n    train_acc = correct_preds / y_train.shape[0]\n\n    print(f'Training accuracy: {(train_acc * 100):.2f}')\n\n    # calculate testing accuracy\n    correct_preds = 0\n    for i in range(len(y_val)):\n        if(y_val[i] == y_val_pred[0][i]):\n            correct_preds += 1\n    test_acc = correct_preds / y_val.shape[0]\n\n    print(f'Test accuracy: {(test_acc * 100):.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict from MLP\ny_train_pred = mlp.predict(emb_train)\ny_val_pred = mlp.predict(emb_val)\n\n#Get the 2 first\ny_train_pred = my_predict(y_train_pred)\ny_val_pred = my_predict(y_val_pred)\n\nEvaluate(y_train_pred,y_val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Knn Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_number = len(emb_train[0])\n\nk = 7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data_train = tf.Variable(emb_train)\ny_data_train = tf.Variable(y_train_onehot)\n\n\naccuracy = 0\n\nfor i in range(0,(len(emb_val)//10)):    \n    x_data_test = tf.Variable(emb_val[i*10:(i+1)*10])\n\n    # manhattan distance\n    distance = tf.reduce_sum(tf.abs(tf.subtract(x_data_train, tf.expand_dims(x_data_test, 1))), axis=2)\n\n    # nearest k points\n    _, top_k_indices = tf.nn.top_k(tf.negative(distance), k=k)\n    top_k_label = tf.gather(y_data_train, top_k_indices)\n\n    sum_up_predictions = tf.reduce_sum(top_k_label, axis=1)\n    prediction = tf.argmax(sum_up_predictions, axis=1)\n\n    for pred, actual in zip(prediction, y_val_onehot[i*10:(i+1)*10]):\n        if pred == np.argmax(actual):\n            accuracy += 1\n\n            \nprint(accuracy)\nprint(accuracy / len(emb_val))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}