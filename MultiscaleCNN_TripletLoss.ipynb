{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libs"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nprint(tf.__version__)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers \nimport tensorflow_addons as tfa\n\nfrom keras.regularizers import l2\nfrom keras.utils import to_categorical\nfrom keras.models import load_model\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Name of files and your labels"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"X_train = np.load('/kaggle/input/birdclef-2020/X_train.npy')\ny_train = np.load('/kaggle/input/birdclef-2020/y_train.npy')\n\nX_val = np.load('/kaggle/input/birdclef-2020/X_val.npy')\ny_val = np.load('/kaggle/input/birdclef-2020/y_val.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Organize data to all batchs have positives and negatives anchors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort by Label\ny_train,X_train = (list(t) for t in zip(*sorted(zip(y_train, X_train))))\ny_val,X_val = (list(t) for t in zip(*sorted(zip(y_val, X_val))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Organize to all batchs have positives and negatives anchors\ntuple_X = []\ntuple_y = []\n\nfor i in range(0,len(y_train),2):\n    if(i == len(y_train)-1):\n        tuple_X.append((X_train[i],X_train[i]))\n        tuple_y.append((y_train[i],y_train[i]))\n    else:    \n        tuple_X.append((X_train[i],X_train[i+1]))\n        tuple_y.append((y_train[i],y_train[i+1]))\n\ntuple_X_shuffled, tuple_y_shuffled = shuffle(tuple_X, tuple_y)\n\nX_shuffled = []\ny_shuffled = []\nfor i in range(0,len(tuple_y_shuffled)):\n    X_shuffled.append(tuple_X_shuffled[i][0])\n    X_shuffled.append(tuple_X_shuffled[i][1])\n    y_shuffled.append(tuple_y_shuffled[i][0])\n    y_shuffled.append(tuple_y_shuffled[i][1])\n\nX_train = np.array(X_shuffled)\ny_train = np.array(y_shuffled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Organize to all batchs have positives and negatives anchors\n\ntuple_X = []\ntuple_y = []\n\nfor i in range(0,len(y_val),2):\n    if(i == len(y_val)-1):\n        tuple_X.append((X_val[i],X_val[i]))\n        tuple_y.append((y_val[i],y_val[i]))\n    else:    \n        tuple_X.append((X_val[i],X_val[i+1]))\n        tuple_y.append((y_val[i],y_val[i+1]))\n\ntuple_X_shuffled, tuple_y_shuffled = shuffle(tuple_X, tuple_y)\n\nX_shuffled = []\ny_shuffled = []\nfor i in range(0,len(tuple_y_shuffled)):\n    X_shuffled.append(tuple_X_shuffled[i][0])\n    X_shuffled.append(tuple_X_shuffled[i][1])\n    y_shuffled.append(tuple_y_shuffled[i][0])\n    y_shuffled.append(tuple_y_shuffled[i][1])\n\nX_val = np.array(X_shuffled)\ny_val = np.array(y_shuffled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make a DataGenerator to get the numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    \n    def __init__(self, image_filenames,labels, image_path,to_fit=True, batch_size=64):\n        self.labels = labels\n        self.image_filenames = image_filenames\n        self.image_path = image_path\n        self.to_fit = to_fit\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n\n    def __getitem__(self, index):\n        # Generate data\n        X = self._generate_X(index)\n\n        if self.to_fit:\n            y = self._generate_y(index)\n            return X, y\n        else:\n            return X\n\n    def _generate_X(self, idx):\n        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n        ret = []\n\n        for file_name in batch_x:\n            dict_data = np.load(self.image_path +str(file_name)+\".npz\")\n            data = dict_data['arr_0']\n            ret.append(data)\n\n        return np.array(ret)\n\n    def _generate_y(self, idx):\n        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n\n        return np.array(batch_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Multiscale CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"wd = 0.000001\n\n#Template of Multiscale Analysis Module\ndef MAM(in_mam):\n    str1 = layers.Conv2D(64,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    \n    str2 = layers.Conv2D(32,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    str2 = layers.Conv2D(64,kernel_size=(3,3),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(str2)\n    \n    str3 = layers.Conv2D(32,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    str3 = layers.Conv2D(64,kernel_size=(5,5),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(str3)\n    \n    str4 = layers.Conv2D(32,kernel_size=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(in_mam)\n    str4 = layers.Conv2D(64,kernel_size=(7,7),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(str4)\n    \n    mam = layers.concatenate([str1,str2,str3,str4])\n    return mam\n\n#BEGIN OF MULTISCALE CNN\nInput = keras.Input(shape=(40, 200, 3))\n\n#CONV1\nx = layers.Conv2D(64, kernel_size=(3,3), strides=(1,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(Input)\n#MAM1\nx = MAM(x)\n#CONV2\nx = layers.Conv2D(64, kernel_size=3,strides=(2,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\n#MAM2\nx = MAM(x)\n#CONV3\nx = layers.Conv2D(64, kernel_size=3,strides=(2,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\n#MAM1\nx = MAM(x)\n#CONV4\nx = layers.Conv2D(64, kernel_size=3,strides=(2,1),padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\n#MAM1\nx = MAM(x)\n#CONV5\nx = layers.Conv2D(64, kernel_size=3,strides=(5,1), padding=\"same\",activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(256,activation='relu',kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\nx = layers.Dense(256,activation='relu', kernel_regularizer=l2(wd), bias_regularizer=l2(wd))(x)\nemb128 = layers.Dense(256,activation='linear')(x)\n\nmodel1 = keras.Model(inputs=Input, outputs=emb128, name=\"Multiscale_CNN\")\n\n#To see the summary of model uncoment here\nmodel1.summary()\n#To see a plot of model uncoment here\n#keras.utils.plot_model(model1, \"deep_metric_learning.png\", show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.compile(\n        optimizer=keras.optimizers.Adagrad(0.001),\n        loss=tfa.losses.TripletSemiHardLoss())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Process"},{"metadata":{"trusted":true},"cell_type":"code","source":"#CallBack to save the weights of model fo each epoch\ncheckpoint_filepath = '/kaggle/working/'\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    'model{epoch:08d}.h5',save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a generator to train and a generator for validation data\nimage_path = '../input/birdclef-2020/train/train/'\nmy_train_generator = DataGenerator(X_train, y_train,image_path,batch_size=32)\nmy_val_generator = DataGenerator(X_val, y_val,image_path,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train\nhistory = model1.fit(my_train_generator,epochs=30,verbose=1,callbacks=[model_checkpoint_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the \"Loss\"\nplt.plot(history.history['loss'][:])\nplt.plot(history.history['val_loss'][:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Uncoment here to save the model in the Disk\n\n# serialize model to JSON\nmodel_json = model1.to_json()\nwith open(\"MultiScale-Triplet.json\", \"w\") as json_file:\n    json_file.write(model_json)\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}